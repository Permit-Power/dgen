{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import contextily as ctx\n",
    "import psycopg2.extras as pgx\n",
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load county mappings\n",
    "county_map = pd.read_csv(\"../../../data/dgen_county_fips_mapping.csv\", dtype={\"geoid10\": str})\n",
    "county_shp = gpd.read_file(\"../../../data/counties\")\n",
    "\n",
    "# Join county shapefile with mapping\n",
    "counties = county_shp[['GEOID', 'NAME', 'geometry']].merge(county_map[['geoid10', 'county_id', 'state_abbr']], right_on='geoid10', left_on='GEOID', how='left')\n",
    "\n",
    "# Load cambium data\n",
    "cambium = pd.read_csv(\"../../../data/cambium.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_shp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "#### Style options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Styling Block ***\n",
    "fmt = '${x:,.0f}'\n",
    "tick = mtick.StrMethodFormatter(fmt)\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 18\n",
    "FIG_SIZE = (12,9) #change figure size throughout for non-faceted figures\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "sns.set_style('white')\n",
    "cp = sns.color_palette() #color palette to use throughout \n",
    "\n",
    "def pull_data(sql,data,con):\n",
    "    out = pd.DataFrame()\n",
    "    for i,r in data.iterrows():\n",
    "        sql_in = sql % (r['scenario'], r['schema'], r['year'])\n",
    "        out = pd.concat([out, pd.read_sql(sql_in, con)])\n",
    "    return out\n",
    "\n",
    "# *** Helper function to easily download dataframes as csv files\n",
    "def create_download_link( df, title = \"Download CSV file\", filename = \"give_me_a_detailed_name.csv\"):  \n",
    "    csv = df.to_csv(index =True)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "#### Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'dgen_db' # if you named your database something else then change the name here\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:postgres@127.0.0.1:5432/{0}\".format(x))\n",
    "con = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schemas\n",
    "dpw_schema      = \"diffusion_results_20250630_180110583487_sheet\"  # $1/W run\n",
    "baseline_schema = \"diffusion_results_20250630_151900462403_sheet\"  # baseline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 1) PV Deployment & Cumulative Bill Savings\n",
    "# -------------------------------------------------------------------\n",
    "sql = \"\"\"\n",
    "WITH a AS (\n",
    "    SELECT *,\n",
    "           new_adopters * first_year_elec_bill_savings AS weighted_bill_savings\n",
    "      FROM {schema}.agent_outputs\n",
    ")\n",
    "SELECT\n",
    "    year,\n",
    "    SUM(system_kw_cum)/1e3       AS deployment_mw,\n",
    "    SUM(weighted_bill_savings)/1e6 AS annual_bill_savings_m\n",
    "FROM a\n",
    "WHERE year BETWEEN 2026 AND 2030\n",
    " and npv > 0\n",
    "GROUP BY year\n",
    "ORDER BY year;\n",
    "\"\"\"\n",
    "\n",
    "# fetch annual deployment & bill savings\n",
    "df_base = pd.read_sql(sql.format(schema=baseline_schema), con)\n",
    "df_dpw  = pd.read_sql(sql.format(schema=dpw_schema),      con)\n",
    "\n",
    "# compute cumulative bill savings\n",
    "df_base[\"cum_bill_savings_m\"] = df_base[\"annual_bill_savings_m\"].cumsum()\n",
    "df_dpw[\"cum_bill_savings_m\"]  = df_dpw[\"annual_bill_savings_m\"].cumsum()\n",
    "\n",
    "# plot cumulative deployment and cumulative bill savings\n",
    "for col, title, ylabel in [\n",
    "    (\"deployment_mw\",      \"Cumulative PV Deployment\",             \"MW\"),\n",
    "    (\"cum_bill_savings_m\", \"Cumulative Bill Savings\",  \"Million $\")\n",
    "]:\n",
    "    # pick the right data from each df\n",
    "    df = (\n",
    "        df_base[[\"year\", col]]\n",
    "        .merge(df_dpw[[\"year\", col]], on=\"year\", suffixes=(\"_base\", \"_dpw\"))\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    ax.plot(df.year, df[f\"{col}_dpw\"],   marker=\"s\", label=\"$1/W\")\n",
    "    ax.plot(df.year, df[f\"{col}_base\"], marker=\"o\", label=\"Baseline\")\n",
    "    ax.set_xticks(df.year)\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(f\"{title}, Delaware (2026–2030)\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) Number of Adopters (weighted)\n",
    "# -------------------------------------------------------------------\n",
    "sql_adopt = \"\"\"\n",
    "SELECT\n",
    "  year,\n",
    "  SUM(number_of_adopters) AS adopters\n",
    "FROM {schema}.agent_outputs\n",
    "WHERE year BETWEEN 2026 AND 2030\n",
    "GROUP BY year\n",
    "ORDER BY year;\n",
    "\"\"\"\n",
    "df_base_adopt = pd.read_sql(sql_adopt.format(schema=baseline_schema), con)\n",
    "df_dpw_adopt  = pd.read_sql(sql_adopt.format(schema=dpw_schema),      con)\n",
    "\n",
    "df_adopt = df_base_adopt.merge(df_dpw_adopt, on=\"year\", suffixes=(\"_base\",\"_dpw\"))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "ax.plot(df_adopt.year, df_adopt.adopters_dpw,   marker=\"s\", label=\"$1/W\")\n",
    "ax.plot(df_adopt.year, df_adopt.adopters_base, marker=\"o\", label=\"Baseline\")\n",
    "ax.set_xticks(df_adopt.year)\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Installations\")\n",
    "ax.set_title(\"Cumulative Number of Installations, Delaware (2026–2030)\")\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### ResStock Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL to get agent level outputs of model runs\n",
    "sql_bldg = \"\"\"\n",
    "SELECT *\n",
    "FROM {schema}.agent_outputs\n",
    "WHERE year BETWEEN 2026 AND 2030\n",
    "    and npv > 0\n",
    "ORDER BY bldg_id;\n",
    "\"\"\"\n",
    "YEAR = 2030\n",
    "# fetch for baseline run\n",
    "df_base_bldg = pd.read_sql(\n",
    "    sql_bldg.format(schema=baseline_schema),\n",
    "    con\n",
    ")\n",
    "\n",
    "# fetch for baseline run\n",
    "df_dpw_bldg = pd.read_sql(\n",
    "    sql_bldg.format(schema=dpw_schema),\n",
    "    con\n",
    ")\n",
    "\n",
    "# 1) BILL SAVINGS: annual savings must be summed across years\n",
    "def agg_bill(df, prefix):\n",
    "    out = (\n",
    "        df.assign(weighted_sav = df.new_adopters * df.first_year_elec_bill_savings)\n",
    "          .groupby(\"county_id\")[\"weighted_sav\"]\n",
    "          .sum()\n",
    "          .reset_index(name=f\"{prefix}_sav_m\")      # millions\n",
    "    )\n",
    "    out[f\"{prefix}_sav_m\"] /= 1e6\n",
    "    return out\n",
    "\n",
    "bill_base = agg_bill(df_base_bldg, \"base\")\n",
    "bill_dpw  = agg_bill(df_dpw_bldg,  \"dpw\")\n",
    "\n",
    "# 2) CUMULATIVE DEPLOYMENT & ADOPTERS: pick year=2030 only\n",
    "def agg_final_year(df, prefix):\n",
    "    df30 = df[df.year == YEAR]\n",
    "    deploy = (\n",
    "        df30.groupby(\"county_id\")[\"system_kw_cum\"]\n",
    "            .sum()\n",
    "            .reset_index(name=f\"{prefix}_deploy_mw\")\n",
    "    )\n",
    "    deploy[f\"{prefix}_deploy_mw\"] /= 1e3   # kW → MW\n",
    "\n",
    "    adop = (\n",
    "        df30.groupby(\"county_id\")[\"number_of_adopters\"]\n",
    "            .sum()\n",
    "            .reset_index(name=f\"{prefix}_adopters\")\n",
    "    )\n",
    "    return deploy.merge(adop, on=\"county_id\")\n",
    "\n",
    "dep_base, dep_dpw = agg_final_year(df_base_bldg, \"base\"), agg_final_year(df_dpw_bldg, \"dpw\")\n",
    "\n",
    "# 3) MERGE EVERYTHING & DIFF\n",
    "df = (\n",
    "    dep_base\n",
    "    .merge(dep_dpw, on=\"county_id\")\n",
    "    .merge(bill_base, on=\"county_id\")\n",
    "    .merge(bill_dpw,  on=\"county_id\")\n",
    ")\n",
    "\n",
    "df[\"diff_deploy_mw\"]  = df[\"dpw_deploy_mw\"]  - df[\"base_deploy_mw\"]\n",
    "df[\"diff_adopters\"]   = df[\"dpw_adopters\"]   - df[\"base_adopters\"]\n",
    "df[\"diff_sav_m\"]      = df[\"dpw_sav_m\"]      - df[\"base_sav_m\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) merge differences onto the geometry\n",
    "gdf = counties.merge(df, on=\"county_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) project to WebMercator for basemap\n",
    "gdf = gdf.to_crs(epsg=3857)\n",
    "\n",
    "xmin, ymin, xmax, ymax = gdf.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) plot\n",
    "vars   = [\"diff_deploy_mw\", \"diff_sav_m\", \"diff_adopters\"]\n",
    "titles = [\"Δ Cumulative PV Deployment (MW)\",\n",
    "          \"Δ Cumulative Bill Savings (M$)\",\n",
    "          \"Δ Cumulative Number of Adopters\"]\n",
    "labels = [\"MW\", \"Million $\", \"Installations\"]\n",
    "\n",
    "pad = 25000\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 8), constrained_layout=True)\n",
    "for ax, var, title, label in zip(axes, vars, titles, labels):\n",
    "    gdf.plot(\n",
    "        column   = var,\n",
    "        ax       = ax,\n",
    "        cmap     = \"Blues\",\n",
    "        legend   = True,\n",
    "        alpha    = 0.5,         # <-- semi-transparent\n",
    "        zorder   = 2,   # <-- draw on top of basemap\n",
    "        legend_kwds={\"shrink\": 0.6, \"label\": label},\n",
    "        missing_kwds={\"color\": \"lightgrey\"},\n",
    "        edgecolor=\"white\",\n",
    "        linewidth=0.2,\n",
    "    )\n",
    "    ax.set_xlim(xmin - pad, xmax + pad)\n",
    "    ax.set_ylim(ymin - pad, ymax + pad) \n",
    "    # add a Positron basemap\n",
    "    ctx.add_basemap(\n",
    "        ax,\n",
    "        source=ctx.providers.CartoDB.Positron,\n",
    "        zoom=9,\n",
    "        crs=gdf.crs, \n",
    "        zorder=1\n",
    "    )\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### GHG savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- parameters ---\n",
    "start_year, end_year = 2026, 2030\n",
    "\n",
    "# --- 1) build an interpolated LRMER lookup from cambium ---\n",
    "# cambium has columns ['state','t','month','hour','lrmer_co2e'], where t in {2025,2030,2035…}\n",
    "#  a) pivot so each (state,month,hour) is a row and t-years are columns\n",
    "years_full = list(range(2025, 2031))   # 2025…2030\n",
    "camb_pivot = (\n",
    "    cambium\n",
    "    .pivot_table(index=['state','month','hour'],\n",
    "                 columns='t',\n",
    "                 values='lrmer_co2e')\n",
    "    .reindex(columns=years_full)       # ensure all years present\n",
    ")\n",
    "# b) linearly interpolate along the year-axis for 2025→2030\n",
    "camb_interp = camb_pivot.interpolate(axis=1, limit_area='inside')\n",
    "# c) melt back and keep only 2026–2030\n",
    "camb_long = (\n",
    "    camb_interp\n",
    "    .reset_index()\n",
    "    .melt(id_vars=['state','month','hour'],\n",
    "          var_name='year',\n",
    "          value_name='lrmer_co2e')\n",
    "    .query('year >= @start_year and year <= @end_year')\n",
    ")\n",
    "# d) final lookup keyed by (state,year,month,hour)\n",
    "lrmer_lookup = camb_long.set_index(\n",
    "    ['state','year','month','hour']\n",
    ")['lrmer_co2e'].to_dict()\n",
    "\n",
    "\n",
    "# --- 2) SQL to fetch agent hourly arrays ---\n",
    "sql_hourly = f\"\"\"\n",
    "SELECT\n",
    "  state_abbr,\n",
    "  year,\n",
    "  system_kw,\n",
    "  new_adopters,\n",
    "  consumption_hourly_list   AS consumption_hourly,\n",
    "  generation_hourly_list    AS generation_hourly,\n",
    "  batt_dispatch_profile_list AS batt_dispatch_profile\n",
    "FROM {{schema}}.agent_outputs\n",
    "WHERE year BETWEEN {start_year} AND {end_year}\n",
    "  AND npv > 0;\n",
    "\"\"\"\n",
    "\n",
    "# --- 3) load both scenarios into pandas ---\n",
    "dfs = {\n",
    "    name: pd.read_sql(sql_hourly.format(schema=schema), con)\n",
    "    for name, schema in [\n",
    "        ('baseline', baseline_schema),\n",
    "        ('dpw',      dpw_schema),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- 4) compute cumulative avoided GHG emissions ---\n",
    "emissions_cum = {}\n",
    "\n",
    "# pre-compute the 8760-hour DatetimeIndex for each year\n",
    "calendars = {\n",
    "    y: pd.date_range(f'{y}-01-01', periods=8760, freq='h')\n",
    "    for y in range(start_year, end_year+1)\n",
    "}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    annual = []\n",
    "    for year in range(start_year, end_year+1):\n",
    "        df_y = df[df.year == year]\n",
    "        dtidx = calendars[year]\n",
    "        months = dtidx.month\n",
    "        hours  = dtidx.hour\n",
    "\n",
    "        total_avoided_tons = 0.0\n",
    "        for _, row in df_y.iterrows():\n",
    "            w = row['new_adopters']\n",
    "\n",
    "            # parse & weight consumption [kWh]\n",
    "            cons = np.array(ast.literal_eval(row['consumption_hourly']), dtype=float) * w\n",
    "\n",
    "            # parse & weight generation [kWh] = CF_per_kW * system_kw * 1h * w\n",
    "            gen = (\n",
    "                np.array(ast.literal_eval(row['generation_hourly']), dtype=float)\n",
    "                * row['system_kw']\n",
    "                * w\n",
    "            )\n",
    "\n",
    "            # parse & weight battery dispatch [kWh]\n",
    "            batt_raw = row['batt_dispatch_profile']\n",
    "            if not batt_raw or batt_raw == '[]':\n",
    "                batt = np.zeros(8760, dtype=float)\n",
    "            else:\n",
    "                batt = np.array(ast.literal_eval(batt_raw), dtype=float) * w\n",
    "\n",
    "            # net grid draw\n",
    "            net = cons - gen + batt\n",
    "\n",
    "            # avoided grid draw = cons - net = gen - batt\n",
    "            avoided = cons - net  \n",
    "\n",
    "            # pull the interpolated LRMER (kg/MWh → convert to kg/kWh by /1000)\n",
    "            fac = np.array([\n",
    "                lrmer_lookup[(row['state_abbr'], year, m, h)]\n",
    "                for m, h in zip(months, hours)\n",
    "            ], dtype=float) / 1000.0  \n",
    "\n",
    "            # sum avoided * factor [kg], convert to metric tons\n",
    "            total_avoided_tons += (avoided * fac).sum() / 1000.0  \n",
    "\n",
    "        annual.append({'year': year, 'avoided_tons': total_avoided_tons})\n",
    "\n",
    "    df_ann = pd.DataFrame(annual).set_index('year')\n",
    "    emissions_cum[name] = df_ann['avoided_tons'].cumsum()\n",
    "\n",
    "\n",
    "# --- 5) plot cumulative avoided emissions ---\n",
    "years = list(range(start_year, end_year+1))\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(years, emissions_cum['dpw'],      marker='s', label='$1/W')\n",
    "plt.plot(years, emissions_cum['baseline'], marker='o', label='Baseline')\n",
    "plt.xticks(years)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Metric tons CO$_2$e Avoided')\n",
    "plt.title('Cumulative Avoided Emissions by Scenario\\n Delaware, 2026–2030')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dg3n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
